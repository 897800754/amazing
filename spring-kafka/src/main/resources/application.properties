#kafka集群地址spring.kafka.bootstrap-servers=localhost:9092#生产者配置#系列化方式spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer#重试次数spring.kafka.producer.retries=0#采用的ack机制spring.kafka.producer.acks=1#批量提交的数据大小 16kbspring.kafka.producer.batch-size=16384#生产者暂存数据的缓冲区大小spring.kafka.producer.buffer-memory=33554432#消费者配置#默认的消费者组，代码中可以热键修改#spring.kafka.consumer.group-id=test#是否自动提交偏移量#spring.kafka.consumer.enable-auto-commit=false# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常#spring.kafka.consumer.auto-offset-reset=none#消费消息后间隔多长时间提交偏移量#spring.kafka.consumer.auto-commit-interval=100##ack模式：##AckMode针对ENABLE_AUTO_COMMIT_CONFIG=false时生效，有以下几种：##RECORD,每处理一条commit一次##BATCH(默认)每次poll的时候批量提交一次，频率取决于每次poll的调用频率##TIME 每次间隔ackTime的时间去commit##COUNT 累积达到ackCount次的ack去commit##COUNT_TIME ackTime或ackCount哪个条件先满足，就commit##MANUAL listener负责ack，但是背后也是批量上去##MANUAL_IMMEDIATE  listener负责ack，每调用一次，就立即commitspring.kafka.listener.ack-mode=MANUAL#系列化方式spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer